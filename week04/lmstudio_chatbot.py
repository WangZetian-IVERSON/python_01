import streamlit as st
from openai import OpenAI
import re
import json
from datetime import datetime

# æ”¹è¿›çš„UIæ ·å¼ï¼ŒåŒ…å«ä¾§è¾¹æ 
st.markdown("""
<style>
/* ä¸»åº”ç”¨èƒŒæ™¯ */
.stApp {
    background-color: #f8f9fa !important;
}

/* ä¾§è¾¹æ æ ·å¼ */
.css-1d391kg {
    background-color: #2c3e50 !important;
    padding: 1rem !important;
}

/* ä¾§è¾¹æ æ ‡é¢˜ */
.css-1d391kg h1, .css-1d391kg h2, .css-1d391kg h3 {
    color: #ecf0f1 !important;
}

/* ä¾§è¾¹æ æ–‡æœ¬ */
.css-1d391kg .stMarkdown {
    color: #bdc3c7 !important;
}

/* ä¾§è¾¹æ æŒ‰é’® */
.css-1d391kg .stButton > button {
    background-color: #3498db !important;
    color: white !important;
    border-radius: 6px !important;
    border: none !important;
    width: 100% !important;
    margin-bottom: 0.5rem !important;
}

.css-1d391kg .stButton > button:hover {
    background-color: #2980b9 !important;
}

/* ä¸»å†…å®¹åŒºåŸŸ */
.main {
    background-color: #ffffff !important;
    padding: 2rem !important;
}

/* æ ‡é¢˜æ ·å¼ */
h1 {
    color: #2c3e50 !important;
    font-weight: 700 !important;
    background-color: #ecf0f1 !important;
    padding: 1rem !important;
    border-radius: 10px !important;
    text-align: center !important;
}

/* èŠå¤©æ¶ˆæ¯å®¹å™¨ */
[data-testid="chat-message"] {
    background-color: #f8f9fa !important;
    border-radius: 12px !important;
    padding: 1rem !important;
    margin: 1rem 0 !important;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1) !important;
}

/* ç”¨æˆ·æ¶ˆæ¯æ ·å¼ */
[data-testid*="user"] {
    background-color: #e3f2fd !important;
    border-left: 4px solid #2196f3 !important;
}

/* åŠ©æ‰‹æ¶ˆæ¯æ ·å¼ */
[data-testid*="assistant"] {
    background-color: #e8f5e8 !important;
    border-left: 4px solid #4caf50 !important;
}

/* èŠå¤©è¾“å…¥æ¡† */
[data-testid="stChatInput"] {
    background-color: #ffffff !important;
    border: 2px solid #e0e0e0 !important;
    border-radius: 25px !important;
    padding: 0.5rem !important;
}

/* å‘é€æŒ‰é’® */
[data-testid="stChatInput"] button {
    background-color: #2196f3 !important;
    border-radius: 50% !important;
    width: 40px !important;
    height: 40px !important;
}

[data-testid="stChatInput"] button:hover {
    background-color: #1976d2 !important;
    transform: scale(1.05) !important;
}
</style>
""", unsafe_allow_html=True)

# æ·»åŠ é»‘è‰²å­—ä½“æ ·å¼
st.markdown("""
<style>
/* ç¡®ä¿æ‰€æœ‰æ–‡æœ¬éƒ½æ˜¯é»‘è‰² */
.stApp, .main, .block-container, .element-container {
    color: #212529 !important;
}

/* Streamlité»˜è®¤æ–‡æœ¬é¢œè‰² */
p, div, span, h2, h3, h4, h5, h6 {
    color: #212529 !important;
}

/* èŠå¤©æ¶ˆæ¯æ–‡æœ¬é¢œè‰² */
[data-testid="chat-message"] {
    color: #212529 !important;
}

[data-testid="chat-message"] p, 
[data-testid="chat-message"] div, 
[data-testid="chat-message"] span {
    color: #212529 !important;
}

/* èŠå¤©è¾“å…¥æ¡†æ–‡æœ¬ */
[data-testid="stChatInput"] input {
    color: #212529 !important;
}

/* æ€è€ƒè¿‡ç¨‹æ˜¾ç¤º */
.thinking-process {
    background-color: #fff3cd !important;
    border: 1px solid #ffeaa7 !important;
    border-radius: 8px !important;
    padding: 1rem !important;
    margin: 1rem 0 !important;
    color: #212529 !important;
}

.thinking-process h4 {
    color: #856404 !important;
    margin-bottom: 0.5rem !important;
}

.thinking-process p {
    color: #212529 !important;
    margin: 0.5rem 0 !important;
}

/* å¼ºåˆ¶è¦†ç›–Streamlité»˜è®¤æ ·å¼ */
.stMarkdown, .stText, .stCaption {
    color: #212529 !important;
}

/* å¼ºåˆ¶æ‰€æœ‰markdownå†…å®¹ä¸ºé»‘è‰² */
.stMarkdown * {
    color: #212529 !important;
}
</style>
""", unsafe_allow_html=True)

# Point to the local server or DeepSeek API
@st.cache_resource
def get_openai_client():
    """è·å–OpenAIå®¢æˆ·ç«¯ - æ”¯æŒæœ¬åœ°å’Œäº‘ç«¯"""
    try:
        # å°è¯•ä» Streamlit secrets è·å– DeepSeek API é…ç½®
        api_key = st.secrets.get("DEEPSEEK_API_KEY", None)
        if api_key:
            # ä½¿ç”¨ DeepSeek API (äº‘ç«¯ç‰ˆæœ¬)
            client = OpenAI(
                api_key=api_key,
                base_url="https://api.deepseek.com"
            )
            return client, "DeepSeek API", "deepseek-chat"
        else:
            # ä½¿ç”¨æœ¬åœ° LM Studio (æœ¬åœ°ç‰ˆæœ¬)
            client = OpenAI(base_url="http://localhost:1234/v1", api_key="lm-studio")
            return client, "LM Studio", "deepseek/deepseek-r1-0528-qwen3-8b"
    except Exception as e:
        st.error(f"å®¢æˆ·ç«¯åˆå§‹åŒ–é”™è¯¯: {e}")
        return None, "é”™è¯¯", ""

# è·å–å®¢æˆ·ç«¯å’Œæ¨¡å‹ä¿¡æ¯
client, client_type, model_name = get_openai_client()

if not client:
    st.stop()

# é…ç½®é¡µé¢
st.set_page_config(
    page_title="DeepSeek Chatbot",
    page_icon="ğŸ’¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("ğŸ’¬ DeepSeek Chatbot")
st.caption(f"ğŸš€ A Streamlit chatbot powered by DeepSeek R1 model via {client_type}")

# æ˜¾ç¤ºè¿æ¥çŠ¶æ€
if client_type == "DeepSeek API":
    st.success("âœ… å·²è¿æ¥åˆ° DeepSeek äº‘ç«¯API")
elif client_type == "LM Studio":
    st.success("âœ… å·²è¿æ¥åˆ°æœ¬åœ° LM Studio")
else:
    st.error("âŒ è¿æ¥å¤±è´¥")

# ä¾§è¾¹æ  - å†å²å¯¹è¯ç®¡ç†
with st.sidebar:
    st.header("ğŸ“š å¯¹è¯å†å²")
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if "conversations" not in st.session_state:
        st.session_state.conversations = {}
    
    if "current_conversation_id" not in st.session_state:
        st.session_state.current_conversation_id = None
        
    if "conversation_counter" not in st.session_state:
        st.session_state.conversation_counter = 0
    
    # æ–°å»ºå¯¹è¯æŒ‰é’®
    if st.button("ğŸ†• æ–°å»ºå¯¹è¯", use_container_width=True):
        st.session_state.conversation_counter += 1
        new_id = f"conversation_{st.session_state.conversation_counter}"
        current_time = datetime.now().strftime("%H:%M")
        st.session_state.conversations[new_id] = {
            "title": f"å¯¹è¯ {st.session_state.conversation_counter}",
            "time": current_time,
            "messages": [{"role": "assistant", "content": "How can I help you?"}]
        }
        st.session_state.current_conversation_id = new_id
        st.session_state.messages = st.session_state.conversations[new_id]["messages"].copy()
        st.rerun()
    
    # æ˜¾ç¤ºå†å²å¯¹è¯åˆ—è¡¨
    st.subheader("å†å²å¯¹è¯")
    
    if st.session_state.conversations:
        # æŒ‰æ—¶é—´å€’åºæ˜¾ç¤ºå¯¹è¯
        conversations_list = list(st.session_state.conversations.items())
        conversations_list.reverse()
        
        for conv_id, conv_data in conversations_list:
            # åˆ›å»ºå¯¹è¯æŒ‰é’®
            button_text = f"ğŸ’¬ {conv_data['title']} ({conv_data['time']})"
            is_current = conv_id == st.session_state.current_conversation_id
            
            if st.button(
                button_text, 
                key=f"load_{conv_id}",
                use_container_width=True,
                type="primary" if is_current else "secondary"
            ):
                st.session_state.current_conversation_id = conv_id
                st.session_state.messages = st.session_state.conversations[conv_id]["messages"].copy()
                st.rerun()
            
            # åˆ é™¤å¯¹è¯æŒ‰é’®
            if st.button(f"ğŸ—‘ï¸ åˆ é™¤", key=f"delete_{conv_id}"):
                if len(st.session_state.conversations) > 1:
                    del st.session_state.conversations[conv_id]
                    if conv_id == st.session_state.current_conversation_id:
                        # åˆ‡æ¢åˆ°ç¬¬ä¸€ä¸ªå¯ç”¨å¯¹è¯
                        remaining_convs = list(st.session_state.conversations.keys())
                        if remaining_convs:
                            st.session_state.current_conversation_id = remaining_convs[0]
                            st.session_state.messages = st.session_state.conversations[remaining_convs[0]]["messages"].copy()
                        else:
                            st.session_state.current_conversation_id = None
                            st.session_state.messages = [{"role": "assistant", "content": "How can I help you?"}]
                    st.rerun()
                else:
                    st.warning("è‡³å°‘éœ€è¦ä¿ç•™ä¸€ä¸ªå¯¹è¯ï¼")
            
            st.divider()
    else:
        st.info("æš‚æ— å†å²å¯¹è¯ï¼Œç‚¹å‡»ä¸Šæ–¹æŒ‰é’®å¼€å§‹æ–°å¯¹è¯")
    
    # æ¸…ç©ºæ‰€æœ‰å¯¹è¯
    if st.button("ğŸ§¹ æ¸…ç©ºæ‰€æœ‰å¯¹è¯", use_container_width=True):
        if st.session_state.conversations:
            st.session_state.conversations = {}
            st.session_state.current_conversation_id = None
            st.session_state.messages = [{"role": "assistant", "content": "How can I help you?"}]
            st.session_state.conversation_counter = 0
            st.rerun()

def format_deepseek_response(content):
    """Format DeepSeek response to separate thinking and response parts"""
    # Multiple patterns to match different thinking formats
    patterns = [
        r'<think>(.*?)</think>',  # Standard <think> tags
        r'<thinking>(.*?)</thinking>',  # Alternative thinking tags
        r'æ€è€ƒï¼š(.*?)(?=\n\n|\Z)',  # Chinese thinking pattern
        r'Thinking:(.*?)(?=\n\n|\Z)',  # English thinking pattern
    ]
    
    thinking_parts = []
    cleaned_content = content
    
    # Try each pattern
    for pattern in patterns:
        matches = re.findall(pattern, cleaned_content, re.DOTALL | re.IGNORECASE)
        thinking_parts.extend(matches)
        # Remove matched parts from content
        cleaned_content = re.sub(pattern, '', cleaned_content, flags=re.DOTALL | re.IGNORECASE)
    
    # Additional check for incomplete thinking tags (streaming scenario)
    incomplete_think_pattern = r'<think>(.*?)(?!</think>)'
    if '<think>' in content and '</think>' not in content:
        # This is likely an incomplete streaming response
        incomplete_match = re.search(incomplete_think_pattern, content, re.DOTALL)
        if incomplete_match:
            thinking_parts.append(incomplete_match.group(1))
            cleaned_content = re.sub(incomplete_think_pattern, '', cleaned_content, flags=re.DOTALL)
    
    response_content = cleaned_content.strip()
    
    return thinking_parts, response_content

def display_formatted_message(content):
    """Display message with formatted thinking and response parts"""
    # Debug: show raw content structure
    # st.text(f"Raw content: {content[:200]}...")
    
    thinking_parts, response_content = format_deepseek_response(content)
    
    # Display thinking parts in small gray text
    if thinking_parts:
        for i, thinking in enumerate(thinking_parts):
            thinking_text = thinking.strip()
            if thinking_text:
                # Escape HTML characters in thinking content
                thinking_html = thinking_text.replace('\n', '<br>')
                st.markdown(f'''
                <div style="
                    font-size:12px; 
                    color:#666666; 
                    font-style:italic; 
                    margin-bottom:10px; 
                    padding:8px; 
                    background-color:#f8f9fa; 
                    border-left:3px solid #dee2e6;
                    border-radius:4px;">
                    ğŸ¤” <strong>æ€è€ƒè¿‡ç¨‹ {i+1}:</strong><br>
                    {thinking_html}
                </div>
                ''', unsafe_allow_html=True)
    
    # Display response content normally, but check if there's any remaining thinking content
    if response_content:
        # Final check: if response still contains thinking patterns, highlight them
        if '<think>' in response_content or 'æ€è€ƒï¼š' in response_content or 'Thinking:' in response_content:
            st.warning("âš ï¸ æ£€æµ‹åˆ°æœªå®Œå…¨åˆ†ç¦»çš„æ€è€ƒå†…å®¹ï¼Œè¯·æ£€æŸ¥æ ¼å¼")
            st.code(response_content, language="text")
        else:
            st.markdown(response_content)
    elif not thinking_parts:
        # If no thinking parts and no response, show raw content
        st.markdown(content)

if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "How can I help you?"}]

# å¦‚æœæ²¡æœ‰å½“å‰å¯¹è¯ï¼Œåˆ›å»ºç¬¬ä¸€ä¸ªå¯¹è¯
if st.session_state.current_conversation_id is None and not st.session_state.conversations:
    st.session_state.conversation_counter += 1
    new_id = f"conversation_{st.session_state.conversation_counter}"
    current_time = datetime.now().strftime("%H:%M")
    st.session_state.conversations[new_id] = {
        "title": f"å¯¹è¯ {st.session_state.conversation_counter}",
        "time": current_time,
        "messages": st.session_state.messages.copy()
    }
    st.session_state.current_conversation_id = new_id

for msg in st.session_state.messages:
    if msg["role"] == "assistant":
        with st.chat_message("assistant"):
            display_formatted_message(msg["content"])
    else:
        st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input():

    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)
    
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=st.session_state.messages,
            stream=True,
        )
        
        msg = ""
        assistant_message = st.chat_message("assistant")
        message_placeholder = assistant_message.empty()

        for chunk in response:
            if chunk.choices[0].delta.content:
                msg += chunk.choices[0].delta.content
                
                # Update display with formatted content
                with message_placeholder.container():
                    display_formatted_message(msg)
        
        st.session_state.messages.append({"role": "assistant", "content": msg})
        
        # ä¿å­˜åˆ°å½“å‰å¯¹è¯
        if st.session_state.current_conversation_id:
            st.session_state.conversations[st.session_state.current_conversation_id]["messages"] = st.session_state.messages.copy()
            
            # å¦‚æœæ˜¯ç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ï¼Œç”¨å®ƒæ¥å‘½åå¯¹è¯
            user_messages = [m for m in st.session_state.messages if m["role"] == "user"]
            if len(user_messages) == 1:
                # æˆªå–å‰20ä¸ªå­—ç¬¦ä½œä¸ºæ ‡é¢˜
                title = prompt[:20] + "..." if len(prompt) > 20 else prompt
                st.session_state.conversations[st.session_state.current_conversation_id]["title"] = title
                
    except Exception as e:
        st.error(f"APIè°ƒç”¨å¤±è´¥: {e}")
        if "insufficient" in str(e).lower() or "balance" in str(e).lower():
            st.warning("âš ï¸ APIä½™é¢ä¸è¶³ï¼Œè¯·å……å€¼åå†è¯•")
        elif "connection" in str(e).lower():
            st.warning("âš ï¸ ç½‘ç»œè¿æ¥é—®é¢˜ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®")
        else:
            st.info("è¯·æ£€æŸ¥ä»¥ä¸‹é…ç½®ï¼š")
            st.info("- å¦‚æœä½¿ç”¨äº‘ç«¯ç‰ˆæœ¬ï¼Œè¯·ç¡®ä¿é…ç½®äº† DEEPSEEK_API_KEY")
            st.info("- å¦‚æœä½¿ç”¨æœ¬åœ°ç‰ˆæœ¬ï¼Œè¯·ç¡®ä¿ LM Studio æ­£åœ¨è¿è¡Œ")
